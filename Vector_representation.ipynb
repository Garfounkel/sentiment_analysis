{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook for the vector representation of the training set prior the neural network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_feather('pickles/train_3.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tweets, sentiments = tweets['Tweet'], tweets['Sentiment']\n",
    "# train_tweets, sentiments = tweets_16m['text'], tweets_16m['target']\n",
    "\n",
    "all_tweets = train_tweets # + test_tweets\n",
    "tokenizer = Tokenizer(filters=' ')\n",
    "tokenizer.fit_on_texts(all_tweets)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_tweets)\n",
    "\n",
    "sequences = train_sequences # + test_sequences\n",
    "MAX_SEQUENCE_LENGTH = 0\n",
    "for elt in sequences:\n",
    "    if len(elt) > MAX_SEQUENCE_LENGTH:\n",
    "        MAX_SEQUENCE_LENGTH = len(elt)\n",
    "\n",
    "MAX_SEQUENCE_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = pad_sequences(train_sequences, MAX_SEQUENCE_LENGTH)\n",
    "train_sequences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words embeddings\n",
    "\n",
    "Currently loading them from pre-built word embeddings, next step is using our word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# googlenews_w2v = KeyedVectors.load_word2vec_format('data/embeddings/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "tmp_file = get_tmpfile('datastories.300d.word2vec')\n",
    "glove2word2vec('data/embeddings/datastories.twitter.300d.txt', tmp_file)\n",
    "w2v = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EmoLex\n",
    "\n",
    "EmoLex is a text file containing words and a weight for 10 different sentiments tied with the word.\n",
    "\n",
    "To add EmoLex, we append the 10 values to the 300 already existing with the word embeddings value.\n",
    "\n",
    "If the word does not exist in the EmoLex database, we add an array of size 10 and values 0.1 to describe the fact that the word does not describe any sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emolex = pd.read_csv('TP_transfer_learning_2018/EmoLex.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLE\n",
    "\n",
    "Opinion Lexicon English is a database that contains a list of english word used in Positive sentences and Negative sentences. If a word is present in neither, it is described as neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_words = []\n",
    "negative_words = []\n",
    "\n",
    "with open('data/positive-words.txt') as positive_file, open('data/negative-words.txt', encoding='ISO-8859-1') as negative_file:\n",
    "    for _ in range(35):\n",
    "        next(positive_file)\n",
    "        next(negative_file)\n",
    "        \n",
    "    for line in positive_file:\n",
    "        positive_words.append(line)\n",
    "    for line in negative_file:\n",
    "        negative_words.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emoji valence and AFINN\n",
    "\n",
    "Emoji Valence is a json file containing a score between -5 and 5 for emojis\n",
    "AFINN is a text file containing also a score between -5 and 5 for english words\n",
    "\n",
    "These two features are merged together since emojis are not present in AFINN file and the emoji file does not contain emoji. Furthermore, they both use score between -5 and 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/index.json') as emojiFile:\n",
    "    emoji_valence = json.load(emojiFile)\n",
    "\n",
    "emoji_valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn = pd.read_csv('data/AFINN-111.txt', sep='\\t')\n",
    "print(afinn.loc[afinn['word'] == 'abandon'].val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building embedding matrix\n",
    "\n",
    "Here, we build the embedding matrix used in the training steps later with first the 300 values in the words embeddings, and we add to that the 10 values of the EmoLex and a last value for the OLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = to_categorical(sentiments, 3)\n",
    "nb_words = len(word_index) + 1\n",
    "\n",
    "EMBEDDING_DIM = 300\n",
    "EMOLEX_DIM = 10\n",
    "OLE_DIM = 1\n",
    "EMOJI_VALENCE_DIM = 1\n",
    "AFINN_DIM = 1 \n",
    "\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM + EMOLEX_DIM + OLE_DIM + AFINN_DIM))\n",
    "\n",
    "oov = []  # Out of vocabulary\n",
    "oov.append((np.random.rand(EMBEDDING_DIM) * 2.0) - 1.0)\n",
    "oov = oov / np.linalg.norm(oov)\n",
    "\n",
    "empty_emolex = np.full(10, 0.1)\n",
    "\n",
    "print(empty_emolex)\n",
    "print(oov.shape)\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    emoji_val = 0\n",
    "    \n",
    "    word_vector = oov\n",
    "    if word in w2v.vocab:\n",
    "        word_vector = w2v.word_vec(word)\n",
    "\n",
    "    emolex_row = emolex.loc[emolex['word'] == word]\n",
    "    if emolex_row.empty:\n",
    "        word_vector = np.append(word_vector, empty_emolex)\n",
    "    else:\n",
    "        word_vector = np.append(word_vector, emolex_row.values.tolist()[0][1:])\n",
    "    \n",
    "    ole_val = 0\n",
    "    if word in positive_words:\n",
    "        ole_val = 5\n",
    "    elif word in negative_words:\n",
    "        ole_val = -5\n",
    "    word_vector = np.append(word_vector, ole_val)\n",
    "    \n",
    "    afinn_val = 0\n",
    "    afinn_row = afinn.loc[afinn['word'] == word]\n",
    "    if not afinn_row.empty:\n",
    "        afinn_val = afinn_row.val\n",
    "    else:\n",
    "        for emoji in emoji_valence:\n",
    "            if word == emoji['emoji']:\n",
    "                afinn_val = emoji['polarity']\n",
    "    word_vector = np.append(word_vector, afinn_val)\n",
    "    \n",
    "    embedding_matrix[i] = word_vector\n",
    "\n",
    "        \n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
