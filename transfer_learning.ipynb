{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras import Model\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_layer (Embedding)  (None, 32, 300)           11090400  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 300)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 32, 300)           541200    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32, 300)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 32, 300)           541200    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32, 300)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 28803     \n",
      "=================================================================\n",
      "Total params: 12,201,603\n",
      "Trainable params: 1,111,203\n",
      "Non-trainable params: 11,090,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = load_model('pickles/train_3_66.7-emb_dr3_bi_dr5_bi_dr4.h5')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_model(model):\n",
    "    model.pop()\n",
    "    model.pop()\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    dense1 = Dense(150, activation='relu')\n",
    "    dense2 = Dense(7, activation='softmax')\n",
    "\n",
    "    model.add(dense1)\n",
    "    model.add(Flatten())\n",
    "    model.add(dense2)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./pickles/train_3_67.2-emb_dr3_bi_dr5_bi_dr4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_layer (Embedding)  (None, 32, 342)           12643056  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 342)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 32, 300)           591600    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32, 300)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 32, 300)           541200    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32, 300)           0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32, 150)           45150     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4800)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 33607     \n",
      "=================================================================\n",
      "Total params: 13,854,613\n",
      "Trainable params: 1,211,557\n",
      "Non-trainable params: 12,643,056\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "reshape_model(model)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yeah ☺ ️ playing well</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>least not guy try discourage anymore want neve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>uplift still discourage mean listen wrong voic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>... age heyday blood tame ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>embarrassed saw u like knvfkkjg think stalker ...</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-3</td>\n",
       "      <td>really plan make video week tv die phone break...</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>-3</td>\n",
       "      <td>hate idea afraid share</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>regular cheerfulness emotion supper give lady ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>pessimist see difficulty every opportunity opt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>-2</td>\n",
       "      <td>hurt ndoes not mean hurt ndoes not mean not ge...</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Class                                              Tweet  Sentiment\n",
       "0   0      0                              yeah ☺ ️ playing well          0\n",
       "1   1      0  least not guy try discourage anymore want neve...          0\n",
       "2   2      0  uplift still discourage mean listen wrong voic...          0\n",
       "3   3      0                      ... age heyday blood tame ...          0\n",
       "4   4     -2  embarrassed saw u like knvfkkjg think stalker ...         -2\n",
       "5   5     -3  really plan make video week tv die phone break...         -3\n",
       "6   6     -3                             hate idea afraid share         -3\n",
       "7   7      1  regular cheerfulness emotion supper give lady ...          1\n",
       "8   8      1  pessimist see difficulty every opportunity opt...          1\n",
       "9   9     -2  hurt ndoes not mean hurt ndoes not mean not ge...         -2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_feather('pickles/train_7.feather')\n",
    "tweets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets, sentiments = tweets['Tweet'], tweets['Sentiment']\n",
    "\n",
    "tokenizer = Tokenizer(filters=' ')\n",
    "tokenizer.fit_on_texts(train_tweets)\n",
    "sequences = tokenizer.texts_to_sequences(train_tweets)\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 0\n",
    "for elt in sequences:\n",
    "    if len(elt) > MAX_SEQUENCE_LENGTH:\n",
    "        MAX_SEQUENCE_LENGTH = len(elt)\n",
    "\n",
    "train_sequences = pad_sequences(train_sequences, 32)\n",
    "targets = to_categorical(sentiments, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1630, 32)\n",
      "(1630, 7)\n"
     ]
    }
   ],
   "source": [
    "print(train_sequences.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: 1141 samples\n",
      "validation set: 489 samples\n",
      "x_train: (1141, 32)\n",
      "y_train: (1141, 7)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_sequences, targets, test_size=0.3)\n",
    "\n",
    "print('training set: ' + str(len(X_train)) + ' samples')\n",
    "print('validation set: ' + str(len(X_val)) + ' samples')\n",
    "\n",
    "print('x_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1141 samples, validate on 489 samples\n",
      "Epoch 1/5\n",
      "1141/1141 [==============================] - 9s 8ms/step - loss: 1.8014 - acc: 0.2857 - val_loss: 1.8699 - val_acc: 0.2454\n",
      "Epoch 2/5\n",
      "1141/1141 [==============================] - 9s 8ms/step - loss: 1.7762 - acc: 0.2971 - val_loss: 1.8707 - val_acc: 0.2372\n",
      "Epoch 3/5\n",
      "1141/1141 [==============================] - 9s 8ms/step - loss: 1.7471 - acc: 0.2971 - val_loss: 1.8723 - val_acc: 0.2352\n",
      "Epoch 4/5\n",
      "1141/1141 [==============================] - 9s 8ms/step - loss: 1.6970 - acc: 0.3181 - val_loss: 1.8985 - val_acc: 0.2331\n",
      "Epoch 5/5\n",
      "1141/1141 [==============================] - 10s 8ms/step - loss: 1.6239 - acc: 0.3497 - val_loss: 1.9601 - val_acc: 0.2454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff23ad500f0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, validation_data=(X_val, y_val), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
