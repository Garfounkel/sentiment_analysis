{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T16:32:04.671400Z",
     "start_time": "2018-10-20T16:32:02.417694Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import *\n",
    "import matplotlib.pyplot as plt\n",
    "from tokenizer import tokenizer\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "PATH = '/home/epita/sim/sentiment_analysis/data/'\n",
    "DETAILED_TRN_PATH = f'{PATH}/2018-Valence-oc-En-train.csv'\n",
    "DETAILED_VAL_PATH = f'{PATH}/2018-Valence-oc-En-dev.csv'\n",
    "\n",
    "TRN_PATH = f'{PATH}/training.1600000.processed.noemoticon.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T16:32:55.744704Z",
     "start_time": "2018-10-20T16:32:55.731123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[6, 2, 7, 1, 4, 4, 6, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "text = 'The quick brown fox jumped over the lazy dog.'\n",
    "\n",
    "words = set(text_to_word_sequence(text))\n",
    "vocab_size = len(words)\n",
    "print(vocab_size)\n",
    "\n",
    "result = one_hot(text, round(vocab_size*1.3))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T16:33:06.008943Z",
     "start_time": "2018-10-20T16:33:05.987578Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog', '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = tokenizer.TweetTokenizer()\n",
    "\n",
    "T.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:09:53.111161Z",
     "start_time": "2018-10-17T14:09:53.064319Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(TRN_PATH, sep=='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:18:30.994749Z",
     "start_time": "2018-10-17T14:18:30.969591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Affect Dimension</th>\n",
       "      <th>Intensity Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2017-En-30021</td>\n",
       "      <td>When you wake up from a dream laughing at some...</td>\n",
       "      <td>valence</td>\n",
       "      <td>3: very positive emotional state can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>2017-En-31387</td>\n",
       "      <td>Good morning! Welcome the new day into your li...</td>\n",
       "      <td>valence</td>\n",
       "      <td>3: very positive emotional state can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2017-En-20042</td>\n",
       "      <td>@danisnotonfire you made me cry and shake to t...</td>\n",
       "      <td>valence</td>\n",
       "      <td>-3: very negative emotional state can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>2017-En-30135</td>\n",
       "      <td>@LindseySanford @simplymeasured this makes me ...</td>\n",
       "      <td>valence</td>\n",
       "      <td>2: moderately positive emotional state can be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>2017-En-40740</td>\n",
       "      <td>the rappers who stayed true to the game is rich.</td>\n",
       "      <td>valence</td>\n",
       "      <td>1: slightly positive emotional state can be in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID                                              Tweet  \\\n",
       "75    2017-En-30021  When you wake up from a dream laughing at some...   \n",
       "1165  2017-En-31387  Good morning! Welcome the new day into your li...   \n",
       "63    2017-En-20042  @danisnotonfire you made me cry and shake to t...   \n",
       "659   2017-En-30135  @LindseySanford @simplymeasured this makes me ...   \n",
       "668   2017-En-40740   the rappers who stayed true to the game is rich.   \n",
       "\n",
       "     Affect Dimension                                    Intensity Class  \n",
       "75            valence   3: very positive emotional state can be inferred  \n",
       "1165          valence   3: very positive emotional state can be inferred  \n",
       "63            valence  -3: very negative emotional state can be inferred  \n",
       "659           valence  2: moderately positive emotional state can be ...  \n",
       "668           valence  1: slightly positive emotional state can be in...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sequential()\n",
    "Embedding(len(word_index) + 1, EMBEDDING_PATH...?, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False)\n",
    "LSTM(32)\n",
    "Dropout(0.2)\n",
    "Dense(32, 'relu')\n",
    "Dropout(0.2)\n",
    "Dense(3, activation='softmax')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['acc'])\n",
    "\n",
    "model.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer:\n",
    "\n",
    "model.layers.pop()\n",
    "model.layers.pop()\n",
    "Dense(150, 'relu')\n",
    "Dense(64, 'relu')\n",
    "Dense(7, 'softmax')\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics['accuracy'])\n",
    "\n",
    "# télécharger 50 millions de tweets pour le word2vec\n",
    "\n",
    "#metric pour le script du prof: pearson\n",
    "#utiliser pearson au lieu d'accuracy\n",
    "\n",
    "# l'année dernière le prof a eu 78% accuracy en "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produire un fichier avec les mêmes noms de cartégories sur un fichier de test façon kaggle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
